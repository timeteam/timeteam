---
layout: post
title: "Nick Bostrom - Superintelligence"
date: 2016-04-08
published: true
---


***
<b>Nick Bostrom</b> 2014. _Superintelligence. Paths, Dangers, Strategies_.  Oxford: Oxford University Press. 328 pp.

***
An ambitious bookk about a topic normally reserved for science fiction writers: Is it plausible that artificial intelligence (AI) could one day exceed human capabilities? What would be the consequences?  What should we do about it?  No doubt many would consider this should remain within the realm of science fiction. Not so long ago similar voices no doubt would have said the same about nuclear weapons, satellites, antibiotics, transplant surgery, humans walking the surface of the moon, the internet (the what?), smartphones.  

Clearly these are serious questions worth asking (a view shared by the likes of **Bill Gates**, **Max Tegmark**, **Martin Rees**, **Elon Musk**).  **Bostrom**'s method is to think hard about the likely steps along the way, make cogent arguments about the issues and reach the most plausible conclusions.  The result is a book where each of these steps forms a (usually) short, easily digested chapter, notwithstanding the doltish comment from **Tom Chivers** at _The Telegraph_ who classifies himself thus by asserting it is "a damned hard read".  It isn't, although the final chapters do become longer as more difficult material is discussed.  **Bostrom** has provided extensive endnotes and an impressively eclectic bibliography, so much so that nearly every page threatens a potentially long diversion into multiple parallel reading threads. It is no criticism of the preceding text to say that the bibliography is almost the best part of the book.  

Chapter 1 is a short, thorough and very readable survey of the technical history up to now of AI development. Chapter 2, similarly charts likely future paths.  Subsequent chapters discuss different forms that superintelligent AI might take (speed superintelligence, collective superintelligence, quality superintelligence) then proceed to discuss the timing and speed of a future intelligence explosion.  These early chapters gradually accumulate the impression that although clearly deeply considered, nevertheless what is presented here are opinions, some better supported than others.   Skimming over some of the detail could be done without missing the main message.  Each chapter commences with a very short overview of the content to come

Chapter 6 contemplates likely abilities that a superintelligent AI might possess.  Chapter 7 speculates on what goals a a superintelligent AI might have.  Would the outcome of takeover by a superintelligent AI inevitably be doom for humans (chapter 8)?   How could we control it (chapter 9)?  And so on.  

Chapter 14 asks the reader to think about the strategic directions &emdash what long-term science, technology policy decisions should we take, and how to apply these questions to the issue of superintelligent AI?  Chapter 15 more briefly and bluntly asks "What is to be done?". At risk of ruining the suspense, **Bostrom**'s answer: "Will the best of human nature please stand up".

If one were to strive to be critical, most chapters don't arrive at a clear conclusion.  But then, could anyone, on questions such as these? At least **Bostrom** is honest about it.

<p>[incomplete]
<!--
Much more to come on that, elsewhere.  For the moment, and in the spirit of even-handedness, one advocate of the most plausible alternative to plate tectonics <a href="http://www.expansiontectonics.com/index1.html">is here</a> and <a href="http://www.skepticblog.org/2009/11/23/no-growing-earth-but-a-growing-problem-with-science-journalism/">the web abounds with many shrill responses from plate tectonics advocates</a>. 
-->
